2026-01-12T17:37:13.640185Z  INFO bit_llama: üöÄ Bit-Llama started.
2026-01-12T17:37:13.640884Z  INFO bit_llama::train::training_loop: --- Bit-Llama Training (Pure Rust) ---
2026-01-12T17:37:13.640895Z  INFO bit_llama::train::training_loop: Config: Dim=64, Layers=2, Context=16, Batch=2
2026-01-12T17:37:13.640904Z  INFO bit_llama::train::training_loop: Hyperparams: LR=0.0003, Steps=10, Warmup=100, MinLR=0.00001
2026-01-12T17:37:13.640907Z  INFO bit_llama::train::training_loop: üìä Model Size: 0.10M Params
2026-01-12T17:37:13.640921Z  INFO bit_llama::train::training_loop: üíæ Est. VRAM Usage: 513.52 MB (Params: 1.50 + Act: 0.02)
2026-01-12T17:37:13.640924Z  INFO bit_llama::train::training_loop: Initializing Device...
2026-01-12T17:37:13.640930Z  INFO bit_llama::train::training_loop: Device initialized: Cpu
2026-01-12T17:37:13.641167Z  INFO bit_llama::train::training_loop: Loading Tokenizer from: "C:\\Users\\Humin\\.gemini\\antigravity\\scratch\\new-ai-project\\Bit-TTT\\data\\smoke_test\\tokenizer.json"
2026-01-12T17:37:13.641203Z  WARN bit_llama::train::training_loop: ‚ö†Ô∏è Tokenizer not found! Specific path: "C:\\Users\\Humin\\.gemini\\antigravity\\scratch\\new-ai-project\\Bit-TTT\\data\\smoke_test\\tokenizer.json"
2026-01-12T17:37:13.641207Z  WARN bit_llama::train::training_loop: ‚ö†Ô∏è Defaulting VOCAB to 16384 (Risk of mismatch!)
2026-01-12T17:37:13.643836Z  INFO bit_llama::loader: BitLoader: Loading "C:\\Users\\Humin\\.gemini\\antigravity\\scratch\\new-ai-project\\Bit-TTT\\data\\smoke_test\\dummy.u32" (Model: u32, Tokens: 1000)
2026-01-12T17:37:13.643849Z  INFO bit_llama::train::training_loop: Data Loaded. Total tokens: 1000
2026-01-12T17:37:13.668623Z  INFO bit_llama::train::training_loop: No checkpoint found. Starting fresh.
2026-01-12T17:37:13.668643Z  INFO bit_llama::train::training_loop: Model initialized. Varmap Key count: 17
2026-01-12T17:37:13.669166Z  INFO bit_llama::train::training_loop: Starting Training Loop (Target: 10 steps, Save every 500 steps)...
2026-01-12T17:37:13.669249Z  INFO bit_llama::train::training_loop: CWD: "C:\\Users\\Humin\\.gemini\\antigravity\\scratch\\new-ai-project\\Bit-TTT"
2026-01-12T17:37:13.669689Z  INFO bit_llama::train::training_loop: üìÅ Output directory: pre_demon_test
2026-01-12T17:37:13.670190Z  INFO bit_llama::train::training_loop: ‚úÖ Project Config saved to: pre_demon_test/project.json
2026-01-12T17:37:13.670561Z  INFO bit_llama::train::training_loop: ‚úÖ Model Config saved to: pre_demon_test/config.json
2026-01-12T17:37:13.678318Z  INFO bit_llama::train::training_loop: ‚úÖ Tokenizer backed up to: pre_demon_test/tokenizer.json (from default path)
2026-01-12T17:37:13.845843Z  INFO bit_llama::train::training_loop: Step    0 | Loss: 10.6677 | LR: 0.0000000 | 191.05 tok/s
2026-01-12T17:37:15.199884Z  INFO bit_llama::train::training_loop: Training complete. Saving final model...
2026-01-12T17:37:15.206769Z  INFO bit_llama::train::training_loop: ‚úÖ Model saved to: pre_demon_test/model.safetensors
2026-01-12T17:37:15.207249Z  INFO bit_llama::train::training_loop: ‚úÖ Project Config saved to: pre_demon_test/project.json
2026-01-12T17:37:15.207573Z  INFO bit_llama::train::training_loop: ‚úÖ Model Config saved to: pre_demon_test/config.json
