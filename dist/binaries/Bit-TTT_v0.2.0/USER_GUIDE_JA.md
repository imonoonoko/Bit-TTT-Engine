# Bit-Llama Studio ユーザーガイド (v0.2.0)

Bit-Llama Studio は、誰でも簡単に **1 bit LLM (BitNet b1.58)** の学習と実験ができるオールインワン・ツールです。
このガイドでは、データの準備から学習、そして対話（推論）までの手順を解説します。

---

## 🚀 はじめに (Getting Started)

1.  **起動**: フォルダ内の `start_gui.bat` (または `Bit-TTT.exe`) をダブルクリックします。
2.  **デモモード**: `start_demo.bat` を使うと、デモ用のプロジェクト構成ですぐに試せます。
    *   **注意**: デモモデル (Sample 10M) は初期状態（ランダムな重み）のため、出力は意味不明な文字列になりますが正常動作です。

---

## 📋 ワークフロー (Workflow)

AIを作るには、以下の4つのステップを左から順番に進めます。

### 1. Data Prep (データの準備)
AIに学ばせる「テキストデータ」と「辞書」を用意します。

1.  **📂 Open Raw Folder**:
    *   このボタンを押して開くフォルダに、学習させたいテキストファイル (`.txt`, `.jsonl`) を入れます。
    *   最初は「青空文庫」のテキストや、Wikiのダンプなどがおすすめです。
2.  **🔗 Concatenate Corpus**:
    *   バラバラのファイルを `corpus.txt` という1つのファイルにまとめます。
3.  **🔤 Train Tokenizer**:
    *   **Vocab Size**: 辞書のサイズ。8000 (小さめ) 〜 32000 (標準) を選びます。
    *   **Fast Mode**: チェック推奨。最初の100MBだけを使って高速に辞書を作ります。
    *   ボタンを押すと `tokenizer.json` が生成されます。

### 2. Preprocessing (前処理)
テキストデータを、AIが学習しやすい「数字の形式 (バイナリ)」に変換します。

1.  **Template**:
    *   単なる小説などを読ませる場合はチェック不要 (Text Completion)。
    *   対話データ (`input`/`output`形式) を使う場合は **Alpaca** や **ChatML** を選びます。
2.  **▶ Start Conversion**:
    *   数分かかることがあります。完了すると `train.u32` が生成されます。

### 3. Training (学習)
GPUを使ってAIモデルを鍛えます。

1.  **Profile (プロファイル)**:
    *   **Consumer (8GB VRAM)**: 一般的なPC向け。
    *   **Server (24GB+ VRAM)**: ハイエンドGPU向け。
    *   ここを選ぶだけで、最適なモデルサイズ設定（Dim, Layers）が読み込まれます。
2.  **▶ Start Training**:
    *   学習を開始します。
    *   **Graph**: 中央のグラフで **Loss (損失)** が下がっていくのを見守ります。
        *   Loss > 5.0: まだ言葉を話せません。
        *   Loss < 3.0: 文法を覚え始めます。
        *   Loss < 2.0: かなり自然な文章になります。
3.  **🛑 STOP (Save)**:
    *   いつでも中断できます。データは自動的に保存されます。
    *   `checkpoint_step_XXXX.safetensors` として保存されます。

### 4. Inference (推論・対話)
育てたAIと会話します。

1.  **Load Model**:
    *   `models` フォルダから `.safetensors` ファイルを選びます。
    *   **注意**: 必ず **学習に使ったのと同じ Tokenizer** が同じフォルダにある必要があります。
2.  **Chat**:
    *   下の入力欄にメッセージを入れて Enter で送信！
    *   Parameters (Temperture/Top-P) で創造性を調整できます。

---

## ❓ トラブルシューティング (Troubleshooting)

### Q. 生成される文章が「ざざざ...」や意味不明な記号になる
**A. モデルが未学習（または学習不足）です。**
*   **デモ版 (Sample 10M)** はランダムな状態からスタートするため、最初は意味のある言葉を話せません。
*   自分のモデルでこれが発生する場合は、**Loss が 3.0 以下になるまで学習を続けてください**。
*   言葉を覚えるまでは、宇宙人のような言葉を話すのが「正常な成長過程」です。

### Q. 文字化けする（□ が表示される）
**A. v0.2.0 で修正されました。**
*   古いバージョンでは日本語フォントの一部が表示できない問題（Tofu問題）がありましたが、v0.2.0で修正されています。
*   最新版では、表示できない文字は自動的にフィルタリングされ、□が出ないように対策されています。

### Q. 画面から文字がはみ出る
**A. v0.2.0 で修正されました。**
*   チャット画面のレイアウトを改善し、長い文章も自動的に折り返して表示されるようになりました。

### Q. Training が GPU で動かない (0.00 MB / Cpu)
**A. CUDAドライバを確認してください。**
*   NVIDIA の GPU が必要です。最新のドライバをインストールしてください。
*   v0.2.0 からは、専用カーネルが動かない環境でも標準的な方法でGPUを使う「フォールバックモード」が搭載されています。

---
**Happy Hacking!**
Bit-TTT Team
