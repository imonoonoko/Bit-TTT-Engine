# Bit-Llama Studio

[![Featured on Orynth](https://orynth.dev/api/badge/bit-ttt-engine?theme=dark&style=default)](https://orynth.dev/projects/bit-ttt-engine)

ローカル環境で軽量な大規模言語モデル（LLM）を学習・ファインチューニング・実行するためのオールインワンGUIスタジオです。

## 特徴
- **依存関係ゼロ**: PythonやCUDAのインストール不要（高速化のためには推奨）。単一の `.exe` ファイルのみで動作します。
- **GUIインターフェース**: データ準備、学習、チャット検証をタブ切り替えで直感的に操作可能。
- **日本語完全対応**: 日本語フォントを内蔵し、文字化けのないクリアな表示を実現。
- **視覚的な学習プロセス**: リアルタイムの損失グラフとシステムモニタリング機能を搭載。

## ⚠️ 重要: 互換性と独自のAI技術について
本スタジオは、既存のTransformerやGGUF形式とは異なる**独自の軽量AIアーキテクチャ**を採用しています。
そのため、**このBit-Llama Studioで作成したモデルデータのみが動作します**。既存の`.pth`や`.gguf`ファイルを読み込むことはできませんのでご注意ください。

## 🚧 開発ステータスと展望
現在は**プロトタイプ（試作段階）**です。
- 基本的な学習と推論のサイクルを検証することを主目的としています。
- 将来的には、より大規模なモデル（7B/70Bクラス）の構築や、さらなる高機能化を計画しています。

## インストール方法
1.  `bit_llama.exe` をダウンロードします。
2.  任意のフォルダ（例: `Bit-Llama-Studio`）に配置します。
3.  ダブルクリックして実行してください。

> [!NOTE]
> アプリケーションを初回起動すると、同じフォルダ内に `projects` フォルダが自動生成されます。ここに学習データやモデルが保存されます。

## 使い方
1.  **Data Prep (データ準備)**: Wiki40bなどのサンプルデータをダウンロードするか、独自のテキストファイルをインポートします。
2.  **Preprocessing (前処理)**: データのクリーニングとトークナイズを行います。
3.  **Training (学習)**: ハイパーパラメータを設定して学習を開始します。損失（Loss）のグラフが下がるのを見守りましょう！
4.  **Chat (チャット検証)**: 学習したモデルを「Inference」タブですぐにテストできます。

## トラブルシューティング
- 起動直後にクラッシュする場合は、同じフォルダに生成される `logs/bit_llama.log` を確認してください。
- フォルダへの書き込み権限があることを確認してください。
