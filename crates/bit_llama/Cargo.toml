[package]
name = "bit_llama"
version = "0.1.0"
edition = "2021"

[dependencies]
anyhow = "1.0"
candle-core = { version = "0.8.0" }
candle-nn = { version = "0.8.0" }
tokenizers = { version = "0.22", features = ["http"] }
rand = "0.8"
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
clap = { version = "4.4", features = ["derive"] }
ctrlc = "3.4"
eframe = "0.26"  # GUI framework
egui_plot = "0.26"  # Graph plotting
# ndarray = "0.15"

# Import our local Bit-TTT engine
# Note: We point to the local rust_engine folder
cortex_rust = { path = "../rust_engine" }
memmap2 = "0.9"
fs2 = "0.4"
nvml-wrapper = { version = "0.9", optional = true }
chrono = { version = "0.4.42", features = ["serde"] }
rfd = "0.17.1"
byteorder = "1.5.0"
glob = "0.3"
rayon = "1.8"
indicatif = "0.17"
hf-hub = "0.3"
regex = "1.5"
ureq = "2.9"
tokio = { version = "1", features = ["full"] }
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter"] }
tracing-appender = "0.2"
minijinja = { version = "1.0", features = ["loader"] }
flate2 = "1.0"
zstd = "0.13"

[lib]
path = "src/lib.rs"

[[bin]]
name = "bit_llama"
path = "src/main.rs"

[features]
default = []
cuda = ["candle-core/cuda", "candle-nn/cuda", "dep:nvml-wrapper"]

[dev-dependencies]
tempfile = "3.8"
