# Bit-TTT è„³ã‚¨ãƒ³ã‚¸ãƒ³: é«˜æ€§èƒ½AIã‚³ã‚¢

**1.58-bit é‡å­åŒ– + Test-Time Training (TTT)** ã®Rustå®Ÿè£…ã§ã™ã€‚
æ¬¡ä¸–ä»£ã®åŠ¹ç‡çš„ã§é©å¿œåŠ›ã®ã‚ã‚‹AIãƒ¢ãƒ‡ãƒ«ã‚’æ”¯ãˆã‚‹ã‚³ã‚¢ã‚¨ãƒ³ã‚¸ãƒ³ã§ã™ã€‚

[English](README.md) (è‹±èªã¯ã“ã¡ã‚‰)

---

# ğŸ‡¯ğŸ‡µ æ—¥æœ¬èª: Bit-TTT Engine

## æ¦‚è¦
**Bit-TTT Engine** ã¯ã€Bit-TTTã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®é«˜æ€§èƒ½å®Ÿè£…ç‰ˆã§ã™ã€‚**1.58bité‡å­åŒ–ã«ã‚ˆã‚‹åŠ¹ç‡æ€§**ã¨ã€**Test-Time Training (æ¨è«–æ™‚å­¦ç¿’) ã«ã‚ˆã‚‹é©å¿œæ€§**ã‚’å…¼ã­å‚™ãˆã¦ã„ã¾ã™ã€‚ãƒ†ãƒ³ã‚½ãƒ«æ¼”ç®—ã«ã¯ **Candle** ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ä½¿ç”¨ã—ã€**å®Œå…¨ãªRustç’°å¢ƒ**ã§å­¦ç¿’ã‹ã‚‰æ¨è«–ã¾ã§ã‚’å®Ÿè¡Œã§ãã¾ã™ï¼ˆPythonã¨ã®é€£æºã‚‚ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã¨ã—ã¦ã‚µãƒãƒ¼ãƒˆï¼‰ã€‚

ğŸ“˜ **[ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆæ›¸](ARCHITECTURE_JA.md)** ã‚‚å‚ç…§ã—ã¦ãã ã•ã„ã€‚

## ç‰¹å¾´
*   **End-to-End Rust Pipeline (NEW!)**: ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã€å­¦ç¿’ã€æ¨è«–ã®ã™ã¹ã¦ã‚’ Rust ã®ã¿ã§å®Œçµã€‚Python ã¯ä¸è¦ã§ã™ã€‚
*   **Rust-First & Python-Compatible**: é«˜é€ŸãªRustã‚³ã‚¢ãƒ­ã‚¸ãƒƒã‚¯ã‚’ PyO3 çµŒç”±ã§Pythonã‹ã‚‰åˆ©ç”¨å¯èƒ½ã€‚
*   **Zero-Copy Inference**: éåŠ¹ç‡ãªãƒ‡ãƒ¼ã‚¿ã‚³ãƒ”ãƒ¼ã‚’æ’é™¤ã—ã€é«˜é€Ÿãªæ¨è«–ã‚’å®Ÿç¾ã€‚
*   **Device Support**: **CPU** (AVXæœ€é©åŒ–) ãŠã‚ˆã³ **CUDA** (GPU) ã§ã®å®Ÿè¡Œã‚’ã‚µãƒãƒ¼ãƒˆã€‚
*   **Pure Rust Mode**: Pythonä¾å­˜ãªã—ã§ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«å¯èƒ½ã€‚çµ„ã¿è¾¼ã¿ç”¨é€”ã«æœ€é©ã€‚
*   **Safe**: Rustã®å®‰å…¨æ€§ä¿è¨¼ã«å³å¯†ã«æº–æ‹ ã€‚

## ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£: Pure Rust ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ 

```mermaid
flowchart LR
    A[Text Data] -->|"Rust Tokenizer"| B(Token IDs)
    B -->|"train_llama (Rust)"| W[(Weights)]
    W -->|"bit_llama (Rust)"| D[Fast Inference]
    
    subgraph "Core Engine (cortex_rust)"
        direction TB
        L[Layers]
        M[BitLinear]
        T[Tokenizers]
    end
    
    B -.-> M
```

## ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹æˆ

- **[`rust_engine/`](rust_engine/)**: ã‚³ã‚¢å®Ÿè£… (`cortex_rust`)ã€‚
    - `core_engine.rs`: Candleãƒ™ãƒ¼ã‚¹ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ­ã‚¸ãƒƒã‚¯ã€‚
    - `lib.rs`: å…¬é–‹ API å®šç¾©ã€‚
- **[`bit_llama/`](bit_llama/)**: å­¦ç¿’ãƒ»æ¨è«–ç”¨ã®ã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³Rustãƒã‚¤ãƒŠãƒªã€‚

## ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ (Pure Rust CLI) ğŸš€

Pythonã‚’ä¸€åˆ‡ä½¿ã‚ãšã«ã€å­¦ç¿’ã‹ã‚‰æ¨è«–ã¾ã§ã‚’å®Ÿè¡Œã§ãã¾ã™ï¼

### 1. ãƒ“ãƒ«ãƒ‰
```bash
cd bit_llama
cargo build --release --features cuda
```

### 2. å­¦ç¿’ (train_llama)
`cortex_rust` ã‚¨ãƒ³ã‚¸ãƒ³ã‚’ä½¿ç”¨ã—ã¦ã‚¼ãƒ­ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã¾ã™ã€‚
```bash
# äº‹å‰ã« src/bin/train_llama.rs ã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„
cargo run --release --features cuda --bin train_llama
```
*å‡ºåŠ›: `bit_llama_checkpoint.safetensors`*

### 3. æ¨è«– (bit_llama)
é«˜æ€§èƒ½ãªã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç”Ÿæˆã‚’å®Ÿè¡Œã—ã¾ã™ã€‚
```bash
# config.json, tokenizer.json, model.safetensors ãŒã‚ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æŒ‡å®š
../target/release/bit_llama --model ../models/dummy --prompt "Hello Rust AI" --temp 0.8 --max-tokens 100
```
*ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹: ~1100 tokens/sec (CPU, ãƒ€ãƒŸãƒ¼ãƒ¢ãƒ‡ãƒ«)*

## ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ (Python)

### 1. ãƒ“ãƒ«ãƒ‰ã¨ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
`maturin` ã‚’ä½¿ç”¨ã—ã¦ Python wheel ã‚’ãƒ“ãƒ«ãƒ‰ã—ã¾ã™ã€‚

```bash
cd rust_engine
maturin develop --release
```

### 2. ä½¿ã„æ–¹
```python
import cortex_rust

# è¨­å®š
config = cortex_rust.BitLlamaConfig(
    vocab_size=50257,
    hidden_dim=256,
    num_layers=4,
    inner_lr=0.01
)

# ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ (ãƒ‡ãƒã‚¤ã‚¹æŒ‡å®š: "cpu" ã¾ãŸã¯ "cuda")
model = cortex_rust.BitLlama(config, "path/to/model.safetensors", device="cuda")

# æ¨è«–å®Ÿè¡Œ (ãƒˆãƒ¼ã‚¯ãƒ³IDåˆ—)
tokens = [1, 50, 100]
logits = model.forward(tokens)
print(logits)
```

## é«˜åº¦ãªãƒ“ãƒ«ãƒ‰ã‚ªãƒ—ã‚·ãƒ§ãƒ³

### Pure Rust Binary (Pythonä¾å­˜ãªã—)
Pythoné€£æºã‚’è¡Œã‚ãšã€è»½é‡ãªRustå˜ä½“ãƒã‚¤ãƒŠãƒªã¨ã—ã¦ãƒ“ãƒ«ãƒ‰ã™ã‚‹å ´åˆï¼š

```bash
cargo build --release --no-default-features
```
(`Cargo.toml` ã® `python` æ©Ÿèƒ½ã‚’ç„¡åŠ¹åŒ–ã—ã¾ã™)

### ãƒ‡ãƒã‚¤ã‚¹é¸æŠ
`PyBitLlama` ã®ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿ã§ãƒ‡ãƒã‚¤ã‚¹ã‚’æŒ‡å®šã§ãã¾ã™ï¼š
- `device="cpu"` (çœç•¥æ™‚ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ)
- `device="cuda"` (CUDAç’°å¢ƒãŒå¿…è¦)

---
*Created by Project Bit-TTT.*
