# リスク評価と既知の問題 (Inference Playground)

## 概要
Bit-Llama Studioのチャット機能（Inference Playground）における、潜在的なリスクとエッジケースの評価一覧です。

## 1. モデルロード失敗 (No Checkpoints Found) ⚠️
- **現象**: 「Load Model」ボタンを押しても "Model not loaded" が返される、または "Failed to spawn" エラーが発生する。
- **原因**: プロジェクトの `models/` ディレクトリ内に有効な `.safetensors` または `.bitt` ファイルが一つも存在しない場合、ディレクトリパスがフォールバックとして使用され、エンジン側でロードに失敗する。
- **対策**: トレーニングを少なくとも一度実行し、チェックポイントが生成されていることを確認してください。

## 2. 日本語入力の競合 (IME Input Conflict) ⌨️
- **現象**: 日本語入力中に「Enter」キーで変換を確定した際、メッセージが送信されてしまう。書きかけの文章（例：「こんに」）が送信される。
- **原因**: `egui` の `TextEdit` コンポーネントにおいて、IMEの確定操作とアプリの送信トリガー（Enterキー検知）を厳密に区別できていないため。
- **回避策**: シフトキーを押しながらEnterを押す（改行扱い）か、将来的なアップデートでIMEイベントハンドリングを強化する必要がある。

## 3. 破損ファイルの読み込み (Corrupted File Load) 💾
- **現象**: 読み込み中にエンジンがクラッシュする。
- **原因**: トレーニングプロセスがチェックポイントを書き込んでいる最中（ファイルサイズが増加中）に、そのファイルをチャット機能でロードしようとした場合、不完全なデータを読み込んでエラーが発生する。
- **対策**: トレーニングのステータスが「Saving...」のときはロードを行わない運用を心がける。

## 4. VRAM不足によるクラッシュ (CUDA OOM) 💥
- **現象**: チャットロード時、またはチャット生成中にプロセスが突然終了する。UI上では "Process Exited" と表示される。
- **原因**: トレーニングプロセスがバックグラウンドでVRAMを大量に消費している状態で、さらに推論プロセスを起動したため、GPUメモリが枯渇した。
- **対策**: トレーニング中は推論を行わない、またはVRAM容量に余裕のあるGPUを使用する。

## 5. パス文字コード問題 (Path Encoding) 🔣
- **現象**: ファイルパスに日本語や特殊文字が含まれていると、"File not found" エラーになる。
- **原因**: Windows環境におけるファイルパスのUTF-8扱いと、内部のパス処理ライブラリの整合性が取れていない稀なケース。
- **対策**: プロジェクト名やユーザー名には可能な限り英数字を使用することを推奨。
